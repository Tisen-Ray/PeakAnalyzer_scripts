"""
å³°åˆ†æå™¨ - é‡æ„ç‰ˆæœ¬ï¼Œæ¸…æ™°çš„æ•°æ®æµå’Œé€»è¾‘
"""

import numpy as np
from scipy import optimize, ndimage
from typing import List, Dict, Any, Optional, Tuple
import copy

from core.curve import Curve, Peak


class PeakAnalyzer:
    """å³°åˆ†æå™¨ - æä¾›å³°çš„è¯¦ç»†åˆ†æåŠŸèƒ½"""
    
    def __init__(self):
        pass
    
    def analyze_peak(self, curve: Curve, peak: Peak, 
                    extend_range: float = 2.0, 
                    baseline_method: str = 'çº¿æ€§åŸºçº¿',
                    boundary_method: str = 'è‡ªåŠ¨é€‰æ‹©ï¼ˆåŸºäºçµæ•åº¦ï¼‰',
                    peak_sensitivity: int = 5,
                    noise_tolerance: int = 5,
                    boundary_smoothing: bool = True,
                    calc_theoretical_plates: bool = True,
                    calc_tailing_factor: bool = True,
                    calc_asymmetry_factor: bool = True,
                    calc_resolution: bool = True,
                    calc_capacity_factor: bool = False,
                    calc_selectivity: bool = False) -> Peak:
        """
        ä½¿ç”¨è‰²è°±åˆ†ææ ‡å‡†æ–¹æ³•åˆ†æå•ä¸ªå³°
        
        æ¸…æ™°çš„æ•°æ®æµï¼š
        1. è·å–å¹³æ»‘å‚æ•° â†’ åº”ç”¨åˆ°æ•´ä¸ªæ›²çº¿
        2. ä»å¹³æ»‘æ›²çº¿æå–å³°åŒºåŸŸ
        3. è¾¹ç•Œæ£€æµ‹ï¼ˆå¹³æ»‘æ•°æ®ï¼‰ + ç§¯åˆ†ï¼ˆåŸå§‹æ•°æ®ï¼‰ + FWHMï¼ˆåŸå§‹æ•°æ®ï¼‰
        4. è®¡ç®—è‰²è°±è´¨é‡å‚æ•°
        """
        updated_peak = copy.deepcopy(peak)
        
        try:
            # === ç¬¬1æ­¥ï¼šè·å–å’Œåº”ç”¨å¹³æ»‘å‚æ•° ===
            smoothed_curve_y = self._get_smoothed_curve_data(curve, boundary_smoothing)
            
            # === ç¬¬2æ­¥ï¼šä»å¹³æ»‘æ›²çº¿æå–å³°åŒºåŸŸ ===
            region_data = self._extract_peak_region_clean(curve, peak, extend_range, smoothed_curve_y)
            if not region_data:
                return updated_peak
            
            x_data, y_original, y_smoothed, peak_idx = region_data
            
            # === ç¬¬3æ­¥ï¼šå³°åˆ†æè®¡ç®— ===
            # è¾¹ç•Œæ£€æµ‹ï¼ˆä½¿ç”¨å¹³æ»‘æ•°æ®ï¼‰
            boundaries = self._detect_boundaries_clean(
                x_data, y_smoothed, peak_idx, boundary_method, 
                peak_sensitivity, noise_tolerance
            )
            
            # å³°ç§¯åˆ†ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼ŒåŸºçº¿æ ¡æ­£ï¼‰
            area = self._calculate_peak_area_clean(
                x_data, y_original, boundaries, baseline_method
            )
            
            # FWHMè®¡ç®—ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼Œæ•°å€¼ç²¾ç¡®ï¼‰
            fwhm = self._calculate_fwhm_clean(x_data, y_original, peak_idx)
            
            # === ç¬¬4æ­¥ï¼šæ›´æ–°å³°å‚æ•° ===
            updated_peak.area = area
            updated_peak.fwhm = fwhm
            updated_peak.rt_start = boundaries[0]
            updated_peak.rt_end = boundaries[1]
            
            # === ç¬¬5æ­¥ï¼šè®¡ç®—è‰²è°±è´¨é‡å‚æ•° ===
            self._calculate_chromatographic_parameters(
                updated_peak, x_data, y_original, peak_idx, curve,
                calc_theoretical_plates, calc_tailing_factor, calc_asymmetry_factor,
                calc_resolution, calc_capacity_factor, calc_selectivity
            )
            
            # === ç¬¬6æ­¥ï¼šä¿å­˜å¯è§†åŒ–æ•°æ® ===
            self._save_visualization_data(
                updated_peak, curve, x_data, y_original, boundaries, 
                baseline_method, area, fwhm
            )
            
        except Exception as e:
            print(f"âŒ å³°åˆ†æå¤±è´¥: {e}")
            # è¿”å›åŸºæœ¬æ›´æ–°çš„å³°
            updated_peak.area = getattr(peak, 'area', 0.0)
            updated_peak.fwhm = max(getattr(peak, 'fwhm', 0.1), 0.001)
        
        return updated_peak
    
    # ===== ç¬¬1æ­¥ï¼šå¹³æ»‘æ•°æ®è·å– =====
    def _get_smoothed_curve_data(self, curve: Curve, boundary_smoothing: bool) -> np.ndarray:
        """è·å–å¹³æ»‘åçš„æ›²çº¿æ•°æ®"""
        if not boundary_smoothing:
            return curve.y_values.copy()
        
        # ä¼˜å…ˆçº§1ï¼šsessionçŠ¶æ€ä¸­çš„å¹³æ»‘å‚æ•°
        try:
            import streamlit as st
            working_key = f"working_curve_{curve.curve_id}"
            if working_key in st.session_state:
                working_data = st.session_state[working_key]
                if "smoothing_method" in working_data and "smoothing_params" in working_data:
                    from ui.pages.processing.smoothing import SmoothingProcessor
                    processor = SmoothingProcessor()
                    smoothed_y = processor.methods[working_data["smoothing_method"]](curve.y_values, working_data["smoothing_params"])
                    print(f"ğŸ”§ ä½¿ç”¨sessionå¹³æ»‘å‚æ•°: {working_data['smoothing_method']}")
                    return smoothed_y
        except Exception as e:
            print(f"âš ï¸ sessionå¹³æ»‘å‚æ•°è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2ï¼šcurveå¯¹è±¡ä¸­çš„å¹³æ»‘å‚æ•°
        try:
            if hasattr(curve, 'smoothing_method') and hasattr(curve, 'smoothing_params'):
                from ui.pages.processing.smoothing import SmoothingProcessor
                processor = SmoothingProcessor()
                smoothed_y = processor.methods[curve.smoothing_method](curve.y_values, curve.smoothing_params)
                print(f"ğŸ”§ ä½¿ç”¨curveå¹³æ»‘å‚æ•°: {curve.smoothing_method}")
                return smoothed_y
        except Exception as e:
            print(f"âš ï¸ curveå¹³æ»‘å‚æ•°è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3ï¼šé»˜è®¤è½»åº¦å¹³æ»‘
        try:
            smoothed_y = ndimage.uniform_filter1d(curve.y_values, size=3)
            print(f"ğŸ”§ ä½¿ç”¨é»˜è®¤å¹³æ»‘ï¼ˆç§»åŠ¨å¹³å‡ï¼Œçª—å£=3ï¼‰")
            return smoothed_y
        except:
            print(f"ğŸ”§ å¹³æ»‘å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            return curve.y_values.copy()
    
    # ===== ç¬¬2æ­¥ï¼šå³°åŒºåŸŸæå– =====
    def _extract_peak_region_clean(self, curve: Curve, peak: Peak, extend_range: float, 
                                 smoothed_curve_y: np.ndarray) -> Optional[Tuple]:
        """ä»å¹³æ»‘æ›²çº¿ä¸­æå–å³°åŒºåŸŸ"""
        try:
            # è®¡ç®—æ‰©å±•èŒƒå›´
            if hasattr(peak, 'fwhm') and peak.fwhm > 0:
                extend_width = peak.fwhm * extend_range
            else:
                extend_width = (curve.x_values[-1] - curve.x_values[0]) * 0.05
            
            # ç¡®å®šæå–èŒƒå›´
            start_rt = peak.rt - extend_width
            end_rt = peak.rt + extend_width
            
            # æå–æ•°æ®
            mask = (curve.x_values >= start_rt) & (curve.x_values <= end_rt)
            x_data = curve.x_values[mask]
            y_original = curve.y_values[mask]  # åŸå§‹æ•°æ®
            y_smoothed = smoothed_curve_y[mask]  # å¹³æ»‘æ•°æ®
            
            if len(x_data) < 5:
                return None
            
            # æ‰¾åˆ°å³°åœ¨åŒºåŸŸä¸­çš„ç´¢å¼•
            peak_idx = np.argmin(np.abs(x_data - peak.rt))
            
            return x_data, y_original, y_smoothed, peak_idx
            
        except Exception as e:
            print(f"âŒ å³°åŒºåŸŸæå–å¤±è´¥: {e}")
            return None
    
    # ===== ç¬¬3æ­¥ï¼šå³°åˆ†æè®¡ç®— =====
    def _detect_boundaries_clean(self, x_data: np.ndarray, y_smoothed: np.ndarray, 
                               peak_idx: int, boundary_method: str, 
                               sensitivity: int, noise_tolerance: int) -> Tuple[float, float]:
        """æ¸…æ™°çš„è¾¹ç•Œæ£€æµ‹é€»è¾‘"""
        try:
            if boundary_method == "åˆ‡çº¿æ’‡å–æ³• (Tangent Skim)":
                return self._tangent_skim_method(x_data, y_smoothed, peak_idx, noise_tolerance)
            elif boundary_method == "æŒ‡æ•°æ’‡å–æ³• (Exponential Skim)":
                return self._exponential_skim_method(x_data, y_smoothed, peak_idx, noise_tolerance)
            elif boundary_method == "è°·åˆ°è°·æ³• (Valley-to-Valley)":
                return self._valley_to_valley_method(x_data, y_smoothed, peak_idx, noise_tolerance)
            elif boundary_method == "å‚ç›´åˆ†å‰²æ³• (Perpendicular Drop)":
                return self._perpendicular_drop_method(x_data, y_smoothed, peak_idx, noise_tolerance)
            else:
                # è‡ªåŠ¨é€‰æ‹©
                return self._auto_select_boundary_method(x_data, y_smoothed, peak_idx, sensitivity, noise_tolerance)
        except Exception as e:
            print(f"âŒ è¾¹ç•Œæ£€æµ‹å¤±è´¥: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨5%å³°é«˜
            return self._fallback_boundary_method(x_data, y_smoothed, peak_idx)
    
    def _calculate_peak_area_clean(self, x_data: np.ndarray, y_original: np.ndarray, 
                                 boundaries: Tuple[float, float], baseline_method: str) -> float:
        """æ¸…æ™°çš„å³°é¢ç§¯è®¡ç®—"""
        try:
            # åŸºçº¿æ ¡æ­£ï¼ˆåªå½±å“ç§¯åˆ†ï¼‰
            baseline_y = self._calculate_baseline_clean(x_data, y_original, baseline_method)
            corrected_y = y_original - baseline_y
            
            # ç¡®å®šç§¯åˆ†èŒƒå›´
            left_rt, right_rt = boundaries
            left_idx = np.argmin(np.abs(x_data - left_rt))
            right_idx = np.argmin(np.abs(x_data - right_rt))
            
            if left_idx >= right_idx:
                return 0.0
            
            # æ¢¯å½¢ç§¯åˆ†
            area = np.trapz(
                np.maximum(corrected_y[left_idx:right_idx+1], 0),
                x_data[left_idx:right_idx+1]
            )
            
            return float(max(area, 0.0))
            
        except Exception as e:
            print(f"âŒ é¢ç§¯è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_fwhm_clean(self, x_data: np.ndarray, y_original: np.ndarray, peak_idx: int) -> float:
        """æ¸…æ™°çš„FWHMè®¡ç®— - æ•°å€¼ç²¾ç¡®æ–¹æ³•"""
        try:
            peak_height = y_original[peak_idx]
            
            # ä¼°ç®—åŸºçº¿
            edge_size = max(2, len(y_original) // 10)
            baseline = (np.min(y_original[:edge_size]) + np.min(y_original[-edge_size:])) / 2
            
            # çœŸå®å³°é«˜å’ŒåŠé«˜
            true_height = peak_height - baseline
            half_height = baseline + true_height / 2
            
            # æ•°å€¼æ–¹æ³•æ‰¾åˆ°ç²¾ç¡®äº¤ç‚¹
            left_rt = self._find_intersection_numerical(x_data, y_original, half_height, peak_idx, 'left')
            right_rt = self._find_intersection_numerical(x_data, y_original, half_height, peak_idx, 'right')
            
            if left_rt is not None and right_rt is not None:
                fwhm = right_rt - left_rt
                print(f"âœ… FWHMè®¡ç®—: {fwhm:.4f} (å·¦={left_rt:.4f}, å³={right_rt:.4f})")
                return float(max(fwhm, 0.001))
            
            # å¤‡ç”¨æ–¹æ³•
            return self._estimate_fwhm_backup(x_data, y_original, peak_idx)
            
        except Exception as e:
            print(f"âŒ FWHMè®¡ç®—å¤±è´¥: {e}")
            return 0.001
    
    # ===== è¾…åŠ©æ–¹æ³• =====
    def _calculate_baseline_clean(self, x_data: np.ndarray, y_data: np.ndarray, method: str) -> np.ndarray:
        """åŸºçº¿è®¡ç®—"""
        if method == "çº¿æ€§åŸºçº¿":
            return np.linspace(y_data[0], y_data[-1], len(y_data))
        elif method == "å¤šé¡¹å¼åŸºçº¿":
            try:
                coeffs = np.polyfit(x_data, y_data, 2)
                return np.polyval(coeffs, x_data)
            except:
                return np.linspace(y_data[0], y_data[-1], len(y_data))
        elif method == "æŒ‡æ•°åŸºçº¿":
            try:
                from scipy.optimize import curve_fit
                def exp_func(x, a, b, c):
                    return a * np.exp(b * x) + c
                popt, _ = curve_fit(exp_func, x_data, y_data, 
                                  p0=[y_data[0], 0.01, np.min(y_data)], maxfev=1000)
                return exp_func(x_data, *popt)
            except:
                return np.linspace(y_data[0], y_data[-1], len(y_data))
        else:
            return np.linspace(y_data[0], y_data[-1], len(y_data))
    
    def _find_intersection_numerical(self, x_data: np.ndarray, y_data: np.ndarray, 
                                   target_height: float, peak_idx: int, direction: str) -> Optional[float]:
        """æ•°å€¼æ–¹æ³•æ‰¾åˆ°ç²¾ç¡®äº¤ç‚¹"""
        try:
            if direction == 'left':
                search_indices = range(peak_idx, -1, -1)
            else:
                search_indices = range(peak_idx, len(y_data))
            
            for i in search_indices[:-1]:
                next_i = i - 1 if direction == 'left' else i + 1
                
                if next_i < 0 or next_i >= len(y_data):
                    continue
                
                y1, y2 = y_data[i], y_data[next_i]
                
                # æ£€æŸ¥æ˜¯å¦è·¨è¶Šç›®æ ‡é«˜åº¦
                if (y1 >= target_height >= y2) or (y1 <= target_height <= y2):
                    # çº¿æ€§æ’å€¼
                    if abs(y2 - y1) > 1e-10:
                        t = (target_height - y1) / (y2 - y1)
                        intersection = x_data[i] + t * (x_data[next_i] - x_data[i])
                        
                        # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if x_data[0] <= intersection <= x_data[-1]:
                            return float(intersection)
            
            # æœªæ‰¾åˆ°äº¤ç‚¹ï¼Œè¿”å›è¾¹ç•Œ
            return float(x_data[0] if direction == 'left' else x_data[-1])
            
        except Exception as e:
            print(f"âŒ äº¤ç‚¹è®¡ç®—é”™è¯¯: {e}")
            return None
    
    def _auto_select_boundary_method(self, x_data: np.ndarray, y_data: np.ndarray, 
                                   peak_idx: int, sensitivity: int, noise_tolerance: int) -> Tuple[float, float]:
        """æ ¹æ®çµæ•åº¦è‡ªåŠ¨é€‰æ‹©è¾¹ç•Œæ£€æµ‹æ–¹æ³•"""
        if sensitivity <= 3:
            return self._tangent_skim_method(x_data, y_data, peak_idx, noise_tolerance)
        elif sensitivity <= 6:
            return self._exponential_skim_method(x_data, y_data, peak_idx, noise_tolerance)
        elif sensitivity <= 8:
            return self._valley_to_valley_method(x_data, y_data, peak_idx, noise_tolerance)
        else:
            return self._perpendicular_drop_method(x_data, y_data, peak_idx, noise_tolerance)
    
    def _tangent_skim_method(self, x_data: np.ndarray, y_data: np.ndarray, 
                           peak_idx: int, noise_tolerance: int) -> Tuple[float, float]:
        """åˆ‡çº¿æ’‡å–æ³•"""
        try:
            # ç®€åŒ–å®ç°ï¼šæ‰¾åˆ°æ–œç‡å˜åŒ–æœ€å¤§çš„ç‚¹
            gradient = np.gradient(y_data)
            
            # å·¦ä¾§æœ€å¤§æ­£æ–œç‡ç‚¹
            left_idx = peak_idx
            max_slope = 0
            for i in range(peak_idx, max(0, peak_idx - len(y_data)//3), -1):
                if gradient[i] > max_slope:
                    max_slope = gradient[i]
                    left_idx = i
            
            # å³ä¾§æœ€å¤§è´Ÿæ–œç‡ç‚¹
            right_idx = peak_idx
            min_slope = 0
            for i in range(peak_idx, min(len(y_data), peak_idx + len(y_data)//3)):
                if gradient[i] < min_slope:
                    min_slope = gradient[i]
                    right_idx = i
            
            return float(x_data[left_idx]), float(x_data[right_idx])
        except:
            return self._fallback_boundary_method(x_data, y_data, peak_idx)
    
    def _exponential_skim_method(self, x_data: np.ndarray, y_data: np.ndarray, 
                               peak_idx: int, noise_tolerance: int) -> Tuple[float, float]:
        """æŒ‡æ•°æ’‡å–æ³•"""
        try:
            baseline = (y_data[0] + y_data[-1]) / 2
            threshold = baseline + (y_data[peak_idx] - baseline) * 0.1
            
            # æ‰¾åˆ°é˜ˆå€¼äº¤ç‚¹
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'right')
            
            return float(x_data[left_idx]), float(x_data[right_idx])
        except:
            return self._fallback_boundary_method(x_data, y_data, peak_idx)
    
    def _valley_to_valley_method(self, x_data: np.ndarray, y_data: np.ndarray, 
                               peak_idx: int, noise_tolerance: int) -> Tuple[float, float]:
        """è°·åˆ°è°·æ³•"""
        try:
            # å¯»æ‰¾å·¦è°·
            left_valley_idx = 0
            min_left = float('inf')
            for i in range(peak_idx, max(0, peak_idx - len(y_data)//3), -1):
                if y_data[i] < min_left:
                    min_left = y_data[i]
                    left_valley_idx = i
            
            # å¯»æ‰¾å³è°·
            right_valley_idx = len(y_data) - 1
            min_right = float('inf')
            for i in range(peak_idx, min(len(y_data), peak_idx + len(y_data)//3)):
                if y_data[i] < min_right:
                    min_right = y_data[i]
                    right_valley_idx = i
            
            return float(x_data[left_valley_idx]), float(x_data[right_valley_idx])
        except:
            return self._fallback_boundary_method(x_data, y_data, peak_idx)
    
    def _perpendicular_drop_method(self, x_data: np.ndarray, y_data: np.ndarray, 
                                 peak_idx: int, noise_tolerance: int) -> Tuple[float, float]:
        """å‚ç›´åˆ†å‰²æ³•"""
        try:
            peak_height = y_data[peak_idx]
            baseline = (y_data[0] + y_data[-1]) / 2
            threshold_ratio = 0.01 + (10 - noise_tolerance) * 0.01
            threshold = baseline + (peak_height - baseline) * threshold_ratio
            
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'right')
            
            return float(x_data[left_idx]), float(x_data[right_idx])
        except:
            return self._fallback_boundary_method(x_data, y_data, peak_idx)
    
    def _find_threshold_crossing_simple(self, y_data: np.ndarray, peak_idx: int, 
                                      threshold: float, direction: str) -> int:
        """ç®€å•çš„é˜ˆå€¼äº¤å‰æŸ¥æ‰¾"""
        if direction == 'left':
            for i in range(peak_idx, -1, -1):
                if y_data[i] <= threshold:
                    return i
            return 0
        else:
            for i in range(peak_idx, len(y_data)):
                if y_data[i] <= threshold:
                    return i
            return len(y_data) - 1
    
    def _fallback_boundary_method(self, x_data: np.ndarray, y_data: np.ndarray, peak_idx: int) -> Tuple[float, float]:
        """å¤‡ç”¨è¾¹ç•Œæ£€æµ‹"""
        try:
            # ä½¿ç”¨5%å³°é«˜ä½œä¸ºç®€å•é˜ˆå€¼
            peak_height = y_data[peak_idx]
            baseline = (y_data[0] + y_data[-1]) / 2
            threshold = baseline + (peak_height - baseline) * 0.05
            
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'right')
            
            return float(x_data[left_idx]), float(x_data[right_idx])
        except:
            # æœ€åå¤‡ç”¨ï¼šä½¿ç”¨å³°å‘¨å›´10%èŒƒå›´
            width = len(x_data) // 10
            left_idx = max(0, peak_idx - width)
            right_idx = min(len(x_data) - 1, peak_idx + width)
            return float(x_data[left_idx]), float(x_data[right_idx])
    
    def _estimate_fwhm_backup(self, x_data: np.ndarray, y_data: np.ndarray, peak_idx: int) -> float:
        """FWHMå¤‡ç”¨ä¼°ç®—"""
        try:
            # ä½¿ç”¨90%é«˜åº¦å®½åº¦ä¼°ç®—
            peak_height = y_data[peak_idx]
            threshold = peak_height * 0.9
            
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, threshold, 'right')
            
            width_90 = x_data[right_idx] - x_data[left_idx]
            return float(max(width_90 * 0.6, 0.001))  # FWHM â‰ˆ 90%å®½åº¦ Ã— 0.6
        except:
            return 0.001
    
    # ===== ç¬¬5æ­¥ï¼šè‰²è°±è´¨é‡å‚æ•°è®¡ç®— =====
    def _calculate_chromatographic_parameters(self, peak: Peak, x_data: np.ndarray, y_data: np.ndarray, 
                                            peak_idx: int, curve: Curve, *calc_flags):
        """è®¡ç®—è‰²è°±è´¨é‡å‚æ•°"""
        (calc_theoretical_plates, calc_tailing_factor, calc_asymmetry_factor,
         calc_resolution, calc_capacity_factor, calc_selectivity) = calc_flags
        
        try:
            if calc_theoretical_plates:
                peak.theoretical_plates = self._calc_theoretical_plates(peak.rt, peak.fwhm)
        except: peak.theoretical_plates = 0.0
        
        try:
            if calc_tailing_factor:
                peak.tailing_factor = self._calc_tailing_factor(x_data, y_data, peak_idx)
        except: peak.tailing_factor = 1.0
        
        try:
            if calc_asymmetry_factor:
                peak.asymmetry_factor = self._calc_asymmetry_factor(x_data, y_data, peak_idx)
        except: peak.asymmetry_factor = 1.0
        
        try:
            if calc_resolution:
                peak.resolution = self._calc_resolution(curve, peak)
        except: peak.resolution = 0.0
        
        try:
            if calc_capacity_factor:
                peak.capacity_factor = self._calc_capacity_factor(peak.rt, curve)
        except: peak.capacity_factor = 0.0
        
        try:
            if calc_selectivity:
                peak.selectivity = self._calc_selectivity_factor(curve, peak)
        except: peak.selectivity = 1.0
    
    def _calc_theoretical_plates(self, rt: float, fwhm: float) -> float:
        """ç†è®ºå¡”æ¿æ•° N = 5.54 * (tR / W1/2)Â²"""
        return 5.54 * (rt / fwhm) ** 2 if fwhm > 0 else 0.0
    
    def _calc_tailing_factor(self, x_data: np.ndarray, y_data: np.ndarray, peak_idx: int) -> float:
        """USPæ‹–å°¾å› å­"""
        try:
            peak_height = y_data[peak_idx]
            h_5 = peak_height * 0.05
            
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, h_5, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, h_5, 'right')
            
            w = x_data[right_idx] - x_data[left_idx]
            f = x_data[peak_idx] - x_data[left_idx]
            
            return w / (2 * f) if f > 0 else 1.0
        except:
            return 1.0
    
    def _calc_asymmetry_factor(self, x_data: np.ndarray, y_data: np.ndarray, peak_idx: int) -> float:
        """USPä¸å¯¹ç§°å› å­"""
        try:
            peak_height = y_data[peak_idx]
            h_10 = peak_height * 0.1
            
            left_idx = self._find_threshold_crossing_simple(y_data, peak_idx, h_10, 'left')
            right_idx = self._find_threshold_crossing_simple(y_data, peak_idx, h_10, 'right')
            
            a = x_data[peak_idx] - x_data[left_idx]
            b = x_data[right_idx] - x_data[peak_idx]
            
            return b / a if a > 0 else 1.0
        except:
            return 1.0
    
    def _calc_resolution(self, curve: Curve, current_peak: Peak) -> float:
        """USPåˆ†ç¦»åº¦"""
        try:
            if len(curve.peaks) < 2:
                return 0.0
            
            # æ‰¾åˆ°æœ€è¿‘çš„å³°
            closest_peak = None
            min_distance = float('inf')
            for peak in curve.peaks:
                if peak.peak_id != current_peak.peak_id:
                    distance = abs(peak.rt - current_peak.rt)
                    if distance < min_distance:
                        min_distance = distance
                        closest_peak = peak
            
            if closest_peak is None:
                return 0.0
            
            rt_diff = abs(closest_peak.rt - current_peak.rt)
            width_sum = current_peak.fwhm + closest_peak.fwhm
            
            return 2 * rt_diff / width_sum if width_sum > 0 else 0.0
        except:
            return 0.0
    
    def _calc_capacity_factor(self, rt: float, curve: Curve) -> float:
        """å®¹é‡å› å­"""
        try:
            t0 = min(peak.rt for peak in curve.peaks) if curve.peaks else 1.0
            t0 = max(t0, 0.1)  # é¿å…è¿‡å°çš„t0
            return (rt - t0) / t0
        except:
            return 0.0
    
    def _calc_selectivity_factor(self, curve: Curve, current_peak: Peak) -> float:
        """é€‰æ‹©æ€§å› å­"""
        try:
            if len(curve.peaks) < 2:
                return 1.0
            
            # æ‰¾åˆ°ç›¸é‚»å³°
            adjacent_peak = None
            for peak in curve.peaks:
                if peak.peak_id != current_peak.peak_id:
                    if adjacent_peak is None or abs(peak.rt - current_peak.rt) < abs(adjacent_peak.rt - current_peak.rt):
                        adjacent_peak = peak
            
            if adjacent_peak is None:
                return 1.0
            
            k1 = self._calc_capacity_factor(current_peak.rt, curve)
            k2 = self._calc_capacity_factor(adjacent_peak.rt, curve)
            
            return max(k2, k1) / min(k2, k1) if min(k2, k1) > 0 else 1.0
        except:
            return 1.0
    
    # ===== ç¬¬6æ­¥ï¼šå¯è§†åŒ–æ•°æ®ä¿å­˜ =====
    def _save_visualization_data(self, peak: Peak, curve: Curve, x_data: np.ndarray, 
                               y_data: np.ndarray, boundaries: Tuple[float, float],
                               baseline_method: str, area: float, fwhm: float):
        """ä¿å­˜å¯è§†åŒ–æ•°æ®"""
        try:
            # è®¡ç®—åŸºçº¿ç”¨äºå¯è§†åŒ–
            baseline_y = self._calculate_baseline_clean(x_data, y_data, baseline_method)
            corrected_y = y_data - baseline_y
            
            # æ˜ å°„åˆ°å®Œæ•´æ›²çº¿
            full_baseline = self._map_baseline_to_full_curve(curve, x_data, baseline_y, boundaries)
            
            peak.metadata['visualization_data'] = {
                'peak_region_x': x_data.tolist(),
                'peak_region_y': y_data.tolist(),
                'peak_region_baseline': baseline_y.tolist(),
                'full_curve_baseline': full_baseline.tolist(),
                'corrected_y': corrected_y.tolist(),
                'boundaries': boundaries,
                'integration_method': 'simple_trapezoid',
                'baseline_method': baseline_method
            }
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–æ•°æ®ä¿å­˜å¤±è´¥: {e}")
            # æä¾›é»˜è®¤æ•°æ®
            peak.metadata['visualization_data'] = {
                'peak_region_x': [peak.rt - 0.1, peak.rt, peak.rt + 0.1],
                'peak_region_y': [peak.intensity * 0.1, peak.intensity, peak.intensity * 0.1],
                'peak_region_baseline': [0, 0, 0],
                'full_curve_baseline': [0] * len(curve.x_values),
                'corrected_y': [peak.intensity * 0.1, peak.intensity, peak.intensity * 0.1],
                'boundaries': (peak.rt - 0.1, peak.rt + 0.1),
                'integration_method': 'simple_trapezoid',
                'baseline_method': baseline_method
            }
    
    def _map_baseline_to_full_curve(self, curve: Curve, peak_x_data: np.ndarray, 
                                  peak_baseline_y: np.ndarray, boundaries: Tuple[float, float]) -> np.ndarray:
        """æ˜ å°„åŸºçº¿åˆ°å®Œæ•´æ›²çº¿"""
        full_baseline = np.zeros_like(curve.y_values)
        
        try:
            start_rt, end_rt = boundaries
            start_idx = np.argmin(np.abs(curve.x_values - start_rt))
            end_idx = np.argmin(np.abs(curve.x_values - end_rt))
            
            start_idx = max(0, min(start_idx, len(curve.x_values) - 1))
            end_idx = max(start_idx + 1, min(end_idx, len(curve.x_values) - 1))
            
            if len(peak_x_data) > 1 and len(peak_baseline_y) > 1:
                full_x_region = curve.x_values[start_idx:end_idx+1]
                interpolated_baseline = np.interp(full_x_region, peak_x_data, peak_baseline_y)
                full_baseline[start_idx:end_idx+1] = interpolated_baseline
        except:
            pass
        
        return full_baseline
