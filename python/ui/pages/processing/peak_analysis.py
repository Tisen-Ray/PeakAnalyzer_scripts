"""
å³°åˆ†æå¤„ç†æ¨¡å—
"""
import streamlit as st
import numpy as np
import plotly.graph_objects as go
from typing import Dict, Any
from core.curve import Curve
from core.state_manager import state_manager
from peak_analysis.peak_analyzer import PeakAnalyzer

class PeakAnalysisProcessor:
    """å³°åˆ†æå¤„ç†å™¨"""
    
    def __init__(self):
        self.peak_analyzer = PeakAnalyzer()
    
    def render_peak_analysis(self, curve: Curve) -> bool:
        """æ¸²æŸ“å³°åˆ†æç•Œé¢å¹¶æ‰§è¡Œå¤„ç†"""
        st.markdown("### ğŸ“Š å³°åˆ†æ")
        
        if not curve or not curve.peaks:
            st.warning("è¯·å…ˆè¿›è¡Œå³°æ£€æµ‹")
            return False
        
        # ä½¿ç”¨å‚ç›´å¸ƒå±€ï¼Œé€‚åº”çª„ä¾§è¾¹æ 
        # åˆ†æå‚æ•°
        extend_range = st.slider(
            "æ‰©å±•èŒƒå›´å€æ•°", 
            min_value=1.0, 
            max_value=5.0, 
            value=2.0, 
            step=0.1,
            help="ç›¸å¯¹äºFWHMçš„æ‰©å±•åˆ†æèŒƒå›´å€æ•°"
        )
        
        # è‰²è°±å³°ç§¯åˆ†æ–¹æ³•ï¼ˆè¡Œä¸šæ ‡å‡†ï¼‰
        st.markdown("**å³°ç§¯åˆ†æ–¹æ³•**")
        integration_method = st.selectbox(
            "ç§¯åˆ†æ–¹æ³•",
            ["å‚ç›´åˆ†å‰²æ³•", "è°·åˆ°è°·ç§¯åˆ†", "åˆ‡çº¿åŸºçº¿æ³•", "æŒ‡æ•°è¡°å‡åŸºçº¿", "æ°´å¹³åŸºçº¿æ³•"],
            index=0,
            help="é€‰æ‹©ç¬¦åˆè‰²è°±åˆ†ææ ‡å‡†çš„ç§¯åˆ†æ–¹æ³•"
        )
        
        # åŸºçº¿å¤„ç†ç­–ç•¥
        baseline_method = st.selectbox(
            "åŸºçº¿å¤„ç†",
            ["è‡ªåŠ¨åŸºçº¿", "çº¿æ€§åŸºçº¿", "å¤šé¡¹å¼åŸºçº¿", "æŒ‡æ•°åŸºçº¿", "æ‰‹åŠ¨åŸºçº¿"],
            index=0,
            help="é€‰æ‹©åŸºçº¿æ ¡æ­£æ–¹æ³•"
        )
        
        # å³°è¾¹ç•Œæ£€æµ‹æ–¹æ³•é€‰æ‹©
        st.markdown("**ğŸ”§ å³°è¾¹ç•Œæ£€æµ‹æ–¹æ³•**")
        
        # æä¾›ä¸“ä¸šçš„è‰²è°±æ–¹æ³•é€‰æ‹©
        boundary_method = st.selectbox(
            "è¾¹ç•Œæ£€æµ‹æ–¹æ³•",
            [
                "è‡ªåŠ¨é€‰æ‹©ï¼ˆåŸºäºçµæ•åº¦ï¼‰",
                "åˆ‡çº¿æ’‡å–æ³• (Tangent Skim)",
                "æŒ‡æ•°æ’‡å–æ³• (Exponential Skim)",
                "è°·åˆ°è°·æ³• (Valley-to-Valley)",
                "å‚ç›´åˆ†å‰²æ³• (Perpendicular Drop)"
            ],
            index=0,
            help="é€‰æ‹©è‰²è°±åˆ†ææ ‡å‡†çš„å³°è¾¹ç•Œæ£€æµ‹æ–¹æ³•"
        )
        
        peak_sensitivity = st.slider(
            "æ£€æµ‹çµæ•åº¦",
            min_value=1,
            max_value=10,
            value=5,
            help="æ§åˆ¶è¾¹ç•Œæ£€æµ‹çš„ä¸¥æ ¼ç¨‹åº¦ã€‚ä½å€¼=ä¿å®ˆ(æŠ—å™ªå£°)ï¼Œé«˜å€¼=å®½æ¾(åŒ…å«æ›´å¤šä¿¡å·)"
        )
        
        # æ˜¾ç¤ºæ–¹æ³•è¯´æ˜
        method_descriptions = {
            "åˆ‡çº¿æ’‡å–æ³• (Tangent Skim)": "ğŸ“ æœ€ä¿å®ˆå’Œå‡†ç¡®ï¼Œé€‚ç”¨äºåŸºçº¿æ¼‚ç§»å’Œé‡å å³°",
            "æŒ‡æ•°æ’‡å–æ³• (Exponential Skim)": "ğŸ“ˆ é€‚ç”¨äºæ‹–å°¾å³°ï¼Œå¤„ç†ä¸å¯¹ç§°å³°å½¢",
            "è°·åˆ°è°·æ³• (Valley-to-Valley)": "ğŸ”ï¸ ç»å…¸æ–¹æ³•ï¼Œé€‚ç”¨äºåŸºçº¿å¹³ç¨³çš„æƒ…å†µ",
            "å‚ç›´åˆ†å‰²æ³• (Perpendicular Drop)": "ğŸ“ æœ€ç®€å•ï¼Œé€‚ç”¨äºå¯¹ç§°å³°å½¢",
            "è‡ªåŠ¨é€‰æ‹©ï¼ˆåŸºäºçµæ•åº¦ï¼‰": "ğŸ¤– æ ¹æ®çµæ•åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•"
        }
        
        if boundary_method in method_descriptions:
            st.info(method_descriptions[boundary_method])
        
        # æ·»åŠ é¢å¤–çš„é²æ£’æ€§æ§åˆ¶å‚æ•°
        noise_tolerance = st.slider(
            "å™ªå£°å®¹å¿åº¦",
            min_value=1,
            max_value=10,
            value=5,
            help="æ§åˆ¶å¯¹å°æ³¢åŠ¨çš„å®¹å¿ç¨‹åº¦ã€‚è¾ƒé«˜å€¼å¯ä»¥æ›´å¥½åœ°å¿½ç•¥åŸºçº¿å™ªå£°"
        )
        
        boundary_smoothing = st.checkbox(
            "è¾¹ç•Œå¹³æ»‘å¤„ç†",
            value=True,
            help="å¯ç”¨è¾¹ç•Œæ£€æµ‹å‰çš„æ•°æ®å¹³æ»‘ï¼Œå‡å°‘å°æ³¢åŠ¨å¯¹è¾¹ç•Œæ£€æµ‹çš„å½±å“"
        )
        
        # è‰²è°±å³°è´¨é‡å‚æ•°ï¼ˆè¡Œä¸šæ ‡å‡†ï¼‰
        st.markdown("**è‰²è°±å³°è´¨é‡å‚æ•°**")
        col1, col2 = st.columns(2)
        with col1:
            calc_theoretical_plates = st.checkbox("ç†è®ºå¡”æ¿æ•° (N)", value=True)
            calc_tailing_factor = st.checkbox("æ‹–å°¾å› å­ (Tf)", value=True)
            calc_asymmetry_factor = st.checkbox("ä¸å¯¹ç§°å› å­ (As)", value=True)
        with col2:
            calc_resolution = st.checkbox("åˆ†ç¦»åº¦ (Rs)", value=True)
            calc_capacity_factor = st.checkbox("å®¹é‡å› å­ (k')", value=False)
            calc_selectivity = st.checkbox("é€‰æ‹©æ€§å› å­ (Î±)", value=False)
        
        # æ‰§è¡ŒæŒ‰é’®
        if st.button("ğŸ“Š å¼€å§‹è‰²è°±å³°åˆ†æ", key="analyze_peaks", width='stretch'):
            return self._analyze_peaks_inplace(curve, {
                'extend_range': extend_range,
            'integration_method': integration_method,
            'baseline_method': baseline_method,
            'boundary_method': boundary_method,
            'peak_sensitivity': peak_sensitivity,
            'noise_tolerance': noise_tolerance,
            'boundary_smoothing': boundary_smoothing,
            'calc_theoretical_plates': calc_theoretical_plates,
            'calc_tailing_factor': calc_tailing_factor,
            'calc_asymmetry_factor': calc_asymmetry_factor,
            'calc_resolution': calc_resolution,
            'calc_capacity_factor': calc_capacity_factor,
            'calc_selectivity': calc_selectivity
            })
        
        return False
    
    def _analyze_peaks_inplace(self, curve: Curve, params: Dict[str, Any]) -> bool:
        """å°±åœ°æ‰§è¡Œå³°åˆ†æ"""
        try:
            # å¯¹æ¯ä¸ªå³°è¿›è¡Œåˆ†æï¼ˆä½¿ç”¨å½“å‰å·¥ä½œå‰¯æœ¬ï¼ŒåŒ…å«æ‰€æœ‰å·²åº”ç”¨çš„å¤„ç†ï¼‰
            for peak in curve.peaks:
                # ä½¿ç”¨è‰²è°±åˆ†ææ ‡å‡†æ–¹æ³•ï¼ˆæ‰€æœ‰è®¡ç®—é€»è¾‘éƒ½åœ¨peak_analyzerä¸­ï¼‰
                updated_peak = self.peak_analyzer.analyze_peak(
                    curve=curve,
                    peak=peak,
                    extend_range=params.get('extend_range', 2.0),
                    integration_method=params.get('integration_method', 'å‚ç›´åˆ†å‰²æ³•'),
                    baseline_method=params.get('baseline_method', 'è‡ªåŠ¨åŸºçº¿'),
                    boundary_method=params.get('boundary_method', 'è‡ªåŠ¨é€‰æ‹©ï¼ˆåŸºäºçµæ•åº¦ï¼‰'),
                    peak_sensitivity=params.get('peak_sensitivity', 5),
                    noise_tolerance=params.get('noise_tolerance', 5),
                    boundary_smoothing=params.get('boundary_smoothing', True),
                    calc_theoretical_plates=params.get('calc_theoretical_plates', True),
                    calc_tailing_factor=params.get('calc_tailing_factor', True),
                    calc_asymmetry_factor=params.get('calc_asymmetry_factor', True),
                    calc_resolution=params.get('calc_resolution', True),
                    calc_capacity_factor=params.get('calc_capacity_factor', False),
                    calc_selectivity=params.get('calc_selectivity', False)
                )
                
                # ç›´æ¥æ›¿æ¢å³°å¯¹è±¡
                curve.peaks[curve.peaks.index(peak)] = updated_peak
            
            # æ›´æ–°å­˜å‚¨æ•°æ®
            stored_curve = state_manager.get_curve(curve.curve_id)
            stored_curve.peaks = curve.peaks.copy()
            state_manager.update_curve(stored_curve)
            
            # æ˜¾ç¤ºç»“æœ
            st.success(f"âœ… è‰²è°±å³°åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(curve.peaks)} ä¸ªå³°")
            st.info(f"ğŸ“Š ä½¿ç”¨æ–¹æ³•: ç§¯åˆ†={params['integration_method']}, åŸºçº¿={params['baseline_method']}")
            
            # æ˜¾ç¤ºå³°åˆ†æç»“æœ
            self._show_peak_analysis_result(curve)
            
            return True
            
        except Exception as e:
            st.error(f"âŒ å³°åˆ†æå¤±è´¥: {str(e)}")
            return False
    
    def _show_peak_analysis_result(self, curve: Curve):
        """æ˜¾ç¤ºå³°åˆ†æç»“æœ"""
        st.markdown("**å³°åˆ†æç»“æœ**")
        
        if not curve.peaks:
            st.info("æš‚æ— å³°æ•°æ®")
            return
        
        # å³°åˆ†æç»“æœè¡¨æ ¼ - åŒ…å«è¯¦ç»†çš„ä¸‰ç»´å‚æ•°
        analysis_data = []
        for i, peak in enumerate(curve.peaks):
            analysis_data.append({
                'å³°': i+1,
                'RT': f"{peak.rt:.3f}",
                'å¼ºåº¦': f"{peak.intensity:.0f}",
                'é¢ç§¯': f"{peak.area:.2e}" if peak.area > 1000 else f"{peak.area:.0f}",
                'FWHM': f"{peak.fwhm:.3f}",
                'èµ·å§‹': f"{peak.rt_start:.3f}" if hasattr(peak, 'rt_start') else "N/A",
                'ç»“æŸ': f"{peak.rt_end:.3f}" if hasattr(peak, 'rt_end') else "N/A",
                'SNR': f"{peak.signal_to_noise:.1f}",
                'ç½®ä¿¡åº¦': f"{peak.confidence:.2f}" if hasattr(peak, 'confidence') else "N/A"
            })
        
        import pandas as pd
        df = pd.DataFrame(analysis_data)
        st.dataframe(df, width='stretch', height=min(300, len(analysis_data) * 35 + 40))
        
        # æ˜¾ç¤ºå³°åˆ†æç»Ÿè®¡ä¿¡æ¯
        if len(curve.peaks) > 0:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("åˆ†æå³°æ•°", len(curve.peaks))
            with col2:
                avg_fwhm = sum(peak.fwhm for peak in curve.peaks) / len(curve.peaks)
                st.metric("å¹³å‡FWHM", f"{avg_fwhm:.3f} min")
            with col3:
                avg_snr = sum(peak.signal_to_noise for peak in curve.peaks) / len(curve.peaks)
                st.metric("å¹³å‡SNR", f"{avg_snr:.1f}")
        
        # è¯¦ç»†å³°ä¿¡æ¯å±•ç¤º - ç´§å‡‘å¸ƒå±€
        st.markdown("**è¯¦ç»†å³°ä¿¡æ¯**")
        for i, peak in enumerate(curve.peaks):
            with st.expander(f"å³° {i+1} - RT: {peak.rt:.3f} min", expanded=False):
                # ä½¿ç”¨æ›´ç´§å‡‘çš„å¸ƒå±€
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("RT", f"{peak.rt:.3f} min")
                    st.metric("å¼ºåº¦", f"{peak.intensity:.0f}")
                
                with col2:
                    st.metric("é¢ç§¯", f"{peak.area:.0f}")
                    st.metric("FWHM", f"{peak.fwhm:.3f} min")
                
                with col3:
                    st.metric("SNR", f"{peak.signal_to_noise:.1f}")
                    st.metric("ç½®ä¿¡åº¦", f"{peak.confidence:.2f}")
                
                # å³°è¾¹ç•Œå’ŒFWHMä¿¡æ¯
                st.markdown("**è¾¹ç•Œä¿¡æ¯:**")
                if hasattr(peak, 'rt_start') and hasattr(peak, 'rt_end'):
                    st.write(f"å³°èŒƒå›´: {peak.rt_start:.3f} - {peak.rt_end:.3f} min")
                    st.write(f"å³°å®½åº¦: {peak.rt_end - peak.rt_start:.3f} min")
                
                if hasattr(peak, 'fwhm') and peak.fwhm > 0:
                    fwhm_left = peak.rt - peak.fwhm / 2
                    fwhm_right = peak.rt + peak.fwhm / 2
                    st.write(f"FWHMèŒƒå›´: [{fwhm_left:.3f}, {fwhm_right:.3f}] min")
                
                # è‰²è°±å³°è´¨é‡å‚æ•°
                params = []
                if hasattr(peak, 'theoretical_plates') and peak.theoretical_plates is not None:
                    params.append(f"ç†è®ºå¡”æ¿æ•° (N): {peak.theoretical_plates:.0f}")
                if hasattr(peak, 'asymmetry_factor') and peak.asymmetry_factor is not None:
                    params.append(f"ä¸å¯¹ç§°å› å­ (As): {peak.asymmetry_factor:.3f}")
                if hasattr(peak, 'tailing_factor') and peak.tailing_factor is not None:
                    params.append(f"æ‹–å°¾å› å­ (Tf): {peak.tailing_factor:.3f}")
                if hasattr(peak, 'resolution') and peak.resolution is not None:
                    params.append(f"åˆ†ç¦»åº¦ (Rs): {peak.resolution:.1f}")
                if hasattr(peak, 'capacity_factor') and peak.capacity_factor is not None:
                    params.append(f"å®¹é‡å› å­ (k'): {peak.capacity_factor:.2f}")
                if hasattr(peak, 'selectivity') and peak.selectivity is not None:
                    params.append(f"é€‰æ‹©æ€§å› å­ (Î±): {peak.selectivity:.2f}")
                
                if params:
                    st.markdown("**è‰²è°±è´¨é‡å‚æ•°:**")
                    st.write(" â€¢ ".join(params))
